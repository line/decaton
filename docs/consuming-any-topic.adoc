Consuming Arbitrary Topic
=========================
:base_version: 9.0.0
:modules: common,protocol,processor

This document covers an advanced usage of Decaton processor when you process topics containing records not produced by DecatonClient.

[NOTE]
====
* From Decaton 9.0.0, DecatonClient no longer wraps tasks with DecatonTaskRequest protobuf message.
** The wrapper was a heritage from the time when Kafka didn't support record headers to store task metadata.
** Now task metadata is stored in record headers instead, so there are no differences in wire format between tasks produced by DecatonClient and by other clients.
* Hence, you can just use link:../processor/src/main/java/com/linecorp/decaton/processor/runtime/ProcessorsBuilder.java[ProcessorsBuilder#consuming(String topic, Deserializer<T> deserializer)] to process arbitrary topics in most cases.
** So the expected use cases of this guide are:
*** You need to apply custom task metadata extraction logic. (e.g. Set `scheduledTimeMillis` for delayed processing)
*** You need to access additional information (e.g. record headers) for deserialization
====

By default, Decaton assumes messages are produced by DecatonClient where task metadata is stored as link:../protocol/src/main/proto/decaton.proto[TaskMetadataProto] in record headers.

When you consume a topic not produced by DecatonClient, you can apply custom task metadata extraction logic.

Through this guide, we assume the topic is JSON-serialized and use link:https://github.com/FasterXML/jackson-databind[jackson-databind] for deserialization, but it's trivial to apply to arbitrary formats other than JSON.

== TaskExtractor

First, you need to start by implementing your own link:../processor/src/main/java/com/linecorp/decaton/processor/runtime/TaskExtractor.java[TaskExtractor] to extract a task from raw consumed messages.

[source,java]
.JSONUserEventExtractor.java
----
public class JSONUserEventExtractor implements TaskExtractor<UserEvent> {
    private static final ObjectMapper MAPPER = new ObjectMapper();

    @Override
    public DecatonTask<UserEvent> extract(ConsumedRecord record) {
        try {
            UserEvent event = MAPPER.readValue(record.value(), UserEvent.class);
            TaskMetadata metadata = TaskMetadata.builder()
                                                // Filling timestampMillis is not mandatory, but it would be useful
                                                // when you monitor delivery latency between event production time and event processing time.
                                                .timestampMillis(event.getEventTimestampMillis())
                                                // This field is not mandatory too, but you can track which application produced the task by filling this.
                                                .sourceApplicationId("event-tracker")
                                                // You can set other TaskMetadata fields as you needed
                                                .build();

            return new DecatonTask<>(metadata, event, record.value());
        } catch (IOException e) {
            throw new UncheckedIOException(e);
        }
    }
}
----

[CAUTION]
====
If `TaskExtractor#extract` throws an exception, an error will be logged and the task which was being processed will be discarded.
However the processor will continue to process subsequent tasks.
====

== DecatonProcessor

Second, let's implement a link:../processor/src/main/java/com/linecorp/decaton/processor/DecatonProcessor.java[DecatonProcessor] to process a UserEvent task.

[source,java]
.UserEventProcessor.java
----
public class UserEventProcessor implements DecatonProcessor<UserEvent> {
    @Override
    public void process(ProcessingContext<UserEvent> context, UserEvent task) throws InterruptedException {
        System.out.printf("Noticed %s is %d years old\n",
                          task.getName(),
                          task.getAge());
    }
}
----

As you can see, once you implement TaskExtractor, the implementation of the DecatonProcessor can be done as when you consume a regular Decaton topic.

Lastly, you need to instantiate link:../processor/src/main/java/com/linecorp/decaton/processor/runtime/ProcessorSubscription.java[ProcessorSubscription] as follows.

[source,java]
.UserEventProcessorMain.java
----
...

ProcessorsBuilder.consuming(
        "my-decaton-json-topic",
        // This line is the only difference from regular Decaton processor.
        new JSONUserEventExtractor())
                 .thenProcess(new UserEventProcessor())

...
----

You have to pass TaskExtractor which you implemented above instead of link:../common/src/main/java/com/linecorp/decaton/common/Deserializer.java[Deseiralizer].

== Run Example

Now we are ready to process a JSON topic.

Before trying out, let's download and extract the kafka binary from https://kafka.apache.org/downloads to use `kafka-console-producer.sh`.

After that, let's create `my-decaton-json-topic` then run the example processor and produce a JSON message.

[source,sh]
----
$ ./gradlew shadowJar

$ java -cp build/libs/example-*-all.jar -Dbootstrap.servers=$KAFKA_BOOTSTRAP_SERVERS example.UserEventProcessorMain &

$ /path/to/kafka_dir/bin/kafka-console-producer.sh --broker-list $KAFKA_BOOTSTRAP_SERVERS --topic my-decaton-json-topic

> {"eventTimestampMillis":1571368115079,"name": "daisuke","age": 52}

Noticed daisuke is 52 years old
----
